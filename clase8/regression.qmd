---
  format:
    revealjs: 
      theme: [default, style.scss]
      slide-number: true
      highlight-style: github
      width: 1400
      css:
         - https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.2/font/bootstrap-icons.css
---

##  {.center}

<h1 class="text-indigo-pink">

Anal칤tica de Datos

<h1>

<h2>Regresi칩n Lineal</h2>

::: {style="margin-top:50px"}
### Carlos Cardona Andrade {.text-orange-gold}
:::

# Tabla de contenido

1. [Correlaci칩n](#corr)
2. [Regresi칩n Lineal Simple](#lm)
3. [Regresi칩n Lineal M칰ltiple](#multiple)

# Correlaci칩n {#corr .text-wash-black background="linear-gradient(45deg, #00aadd, #66dd00)"}


## Algunos fundamentos b치sicos de R {.text-lime-cyan}

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

library(tidyverse)
library(readxl)
library(janitor)
hollywood <- read_excel("C:/Users/ccard/Downloads/KEL702-XLS-ENG.xls", sheet = "Exhibit 1")
hollywood <- hollywood %>%
  clean_names()
hollywood <- hollywood %>% rename(us_gross = total_u_s_gross)
hollywood <- hollywood %>% rename(non_us_gross = total_non_u_s_gross)

```

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| code-fold: true

ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```

## Algunos fundamentos b치sicos de R {.text-lime-cyan}

- Podemos utilizar un diagrama de dispersi칩n para realizar un primer an치lisis de la relaci칩n entre dos variables

- El coeficiente de correlaci칩n (lineal) es utilizado para medir la fuerza de la asociaci칩n (lineal) entre dos variables

- La correlaci칩n entre el recaudo en US y el recaudo el primer fin de semana:

```{r}
#| echo: true
cor(hollywood$us_gross,hollywood$opening_gross)
```


## Algunos fundamentos b치sicos de R {.text-lime-cyan}

```{r}
#| echo: true
#| eval: false
#| fig-align: center

# RECUERDEN INSTALAR EL PAQUETE PRIMERO!!!
# install.packages("corrplot")

# Cargamos el paquete
library(corrplot)

# Creemos una base de datos temporal s칩lo con estas 4 variables
hollywood_sub <- hollywood %>% select( us_gross, opening_gross, non_us_gross, budget) 

# Creemos la matriz de correlaciones
corrplot(cor(hollywood_sub ),
         method = "number",
         type = "upper")

```



## Algunos fundamentos b치sicos de R {.text-lime-cyan}
```{r}
#| echo: false
#| eval: true
#| fig-align: center

# RECUERDEN INSTALARLA PRIMERO!!!
# install.packages("corrplot)

# Cargamos el paquete
library(corrplot)

# Creemos una base de datos temporal s칩lo con estas 4 variables
hollywood_sub <- hollywood %>% select( us_gross, opening_gross, non_us_gross, budget) 

# Creemos la matriz de correlaciones
corrplot(cor(hollywood_sub ),
         method = "number",
         type = "upper")

```



## Algunos fundamentos b치sicos de R {.text-lime-cyan}


```{r}
#| echo: false
#| eval: true
#| fig-align: center

library(datasauRus)
library(patchwork)

dino <- datasaurus_dozen %>%
  filter(dataset == "dino")

star <- datasaurus_dozen %>%
  filter(dataset == "star")

hlines <- datasaurus_dozen %>%
  filter(dataset == "h_lines")

dino %>%
  summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
  )



```



```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 7
#| fig-height: 3.5

ggplot(dino, aes(x=x, y=y))+
  geom_point(color = "darkred") + theme_minimal()
```




## Algunos fundamentos b치sicos de R {.text-lime-cyan}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
star %>%
  summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
  )
```

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 7
#| fig-height: 3.5
ggplot(star, aes(x=x, y=y))+
  geom_point(color = "navy") + theme_minimal()

```


## Algunos fundamentos b치sicos de R {.text-lime-cyan}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 7
#| fig-height: 3.5
hlines %>%
  summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
  )
```

```{r}
#| echo: false
#| eval: true
#| fig-align: center

ggplot(hlines, aes(x=x, y=y))+
  geom_point(color = "orange") + theme_minimal()

```



# Regresi칩n Lineal <br>[Simple]{.hl .hl-gold} {#lm .text-wash-black background="linear-gradient(45deg, #f37335, #fdc830)"}

## Partes esenciales de una regresi칩n {.text-orange-gold}

::: columns
::: {.column width="50%"}
### Y  {.text-orange-gold .center}

- Variable dependiente

- Variable resultado

- B치sicamente lo que queremos predecir o explicar

:::

::: {.column .fragment width="50%"}

### X  {.text-orange-gold .center}

- Variable explicatoria

- Predictor

- Variable independiente

- Lo que usamos para predecir o explicar Y
:::
:::


## 쯇or qu칠 una regresi칩n? {.text-orange-gold}

Usualmente ajustamos a una l칤nea por dos razones:

### Predicci칩n

- Predecir el futuro

- Nos enfocamos en Y

- Netflix tratando de predecir la siguiente serie que veremos

### Explicaci칩n

- Explicar el efecto de X en Y

- Nos enfocamos en X

- Netflix evaluando el efecto de la hora del d칤a en la selecci칩n de una serie


# 쮺칩mo? {.text-orange-gold}

1. Graficar X y Y

2. Dibujar una recta que se aproxime a la relaci칩n observada (ojal치 funcione para datos que no est치n en la muestra)

3. Estimar los n칰meros que componen esa recta

4. Interpretar esos n칰meros

```{r}
#| echo: false
library(tidyverse)
library(patchwork)
library(broom)
library(knitr)
cookies <- tibble(happiness = c(0.5, 2, 1, 2.5, 3, 1.5, 2, 2.5, 2, 3),
                  cookies = 1:10)

cookies_data <- cookies
cookies_model <- lm(happiness ~ cookies, data = cookies)
cookies_fitted <- augment(cookies_model)
```



# Cookies and happiness {.text-orange-gold}

```{r}
#| echo: false
#| eval: true

cookies |> 
  knitr::kable(format = "html") |> 
  kableExtra::kable_styling(font_size = 30) # Adjust the font size as needed
```



# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4



cookies_base <- ggplot(cookies_fitted, aes(x = cookies, y = happiness)) +
  geom_point(size = 3) +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 3)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

cookies_base
```




# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

cookies_base +
  geom_smooth(method = lm, color = "#0074D9", formula = y ~ splines::bs(x, 7), se = FALSE)
```

# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

cookies_base +
  geom_smooth(method = "loess", color = "#0074D9", se = FALSE)
```

# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

cookies_base +
  geom_smooth(method = "lm", color = "#0074D9", se = FALSE)
```

# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

cookies_with_residual <- cookies_base +
  geom_smooth(method = "lm", color = "#0074D9", se = FALSE) +
  geom_segment(aes(xend = cookies, yend = .fitted), color = "#FF851B", size = 1)

cookies_with_residual
```

# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

cookies_residual_only <- ggplot(cookies_fitted, aes(x = cookies, y = .resid)) +
  geom_hline(yintercept = 0, color = "#B10DC9", size = 1) +
  geom_point(size = 3) +
  geom_segment(aes(xend = cookies, yend = 0), color = "#FF851B", size = 1) +
  coord_cartesian(xlim = c(0, 10), ylim = c(-1.5, 1.5)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Galletas consumidas", y = "Distance from line") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

cookies_residual_only
```

# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

(cookies_with_residual + labs(title = "Cookies and happiness")) + 
  (cookies_residual_only + labs(title = "Residual errors"))
```

## Pendiente de una recta {.text-orange-gold}

$$
y = mx + b
$$

|     |                                          |
|:---:|:----------------------------------------:|
| $y$ |                Un n칰mero                 |
| $x$ |                Un n칰mero                 |
| $m$ | La pendiente $\frac{\Delta y}{\Delta x}$ |
| $b$ |          El intercepto con $y$           |

## Pendiente de una recta {.text-orange-gold}

::: columns
::: {.column width="50%"}
$$
y = 2x - 1
$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 4.8
#| fig-height: 3.5

ggplot(data = tibble(x = 0:5), aes(x = x)) +
  stat_function(fun = function(x) 2 * x - 1, 
                color = "#BF3984", size = 1.5) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = 0:5) +
  scale_y_continuous(breaks = -1:9) +
  theme(panel.grid.minor = element_blank())
```

:::



::: {.column .fragment width="50%"}
$$
y = -0.5x + 6
$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 4.8
#| fig-height: 3.5

ggplot(data = tibble(x = 0:14), aes(x = x)) +
  stat_function(fun = function(x) -0.5 * x + 6, 
                color = "#BF3984", size = 1.5) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = 0:14) +
  scale_y_continuous(breaks = -1:9) +
  theme(panel.grid.minor = element_blank())
```

:::
:::

## Regresi칩n lineal simple {.text-orange-gold}

$$
Y = \beta_0 + \beta_1 X + \varepsilon
$$

-   $\beta_1$: la pendiente verdadera de la relaci칩n entre $X$ y $Y$

-   $\beta_0$: el intercepto verdadero de la relaci칩n entre $X$ y $Y$

-   $\varepsilon$: el error

## Regresi칩n lineal simple {.text-orange-gold}

$$
\hat{y} = \hat{\beta_0} + \hat{\beta_1} x_1 
$$

-   $\hat{\beta_1}$: la pendiente estimado de la relaci칩n entre $X$ y $Y$

-   $\hat{\beta_0}$: el intercepto estimado de la relaci칩n entre $X$ y $Y$

-   No hay error!!!

## Modelo de Regresi칩n {.text-orange-gold}

::: columns
::: {.column width="40%"}
$$  
  \begin{aligned}
Y &= \color{#0074D9}{\text{Modelo}} + \color{#FF851B}{\text{Error}} \\
  &= \color{#0074D9}{f(X)} + \color{#FF851B}{\varepsilon}
\end{aligned}
$$
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| out-width: "100%"


cookies_with_residual
```
:::
:::

## Residuos {.text-orange-gold}

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| out-width: "100%"


cookies_with_residual
```

$$
\text{Residuo} = \text{Observado} - \text{Predicho} = y - \hat{y}
$$

## La l칤nea de los m칤nimos cuadrados {.text-orange-gold}

-   El residuo para la observaci칩n $i^{th}$ es:

$$e_i= \text{Observado} - \text{Predicho}=y_i - \hat{y_i}$$ - La **suma de los residuos al cuadrado** es:

$$e_1^2+e_2^2+e_3^2+..+e_n^2$$

-   La **l칤nea de los m칤nimos cuadrados** es la que minimiza la suma de los residuos al cuadrado

## 

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("images/meme.png")

```

## Construyendo modelos en R {.text-orange-gold}

-   La sint치xis para los resultados del modelo es:

```{r}
#| eval: false
#| echo: true

name_of_model <- lm(Y ~ X, data = DATA)

summary(name_of_model)  # Para ver los detalles del modelo
```

::: fragment
-   Otras opciones para evaluar el modelo son:

```{r}
#| eval: false
#| echo: true

library(broom)

# Convierte los resultados del modelo a un data frame para graficar
tidy(name_of_model)

# Convierte los diagn칩sticos del modelo a un data frame
glance(name_of_model)
```
:::

## Modelando Galletas y Felicidad {.text-orange-gold}

::: columns
::: {.column width="40%"}
$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas$$

```{r}
#| echo: true
#| eval: true
happiness_model <- 
  lm(happiness ~ cookies,
     data = cookies_data)
```
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| label: cookies-happiness-again
#| results: hide


cookies_base +
  geom_smooth(method = "lm", color = "#0074D9") +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 4))
```
:::
:::

## Modelando Galletas y Felicidad {.text-orange-gold}

```{r}
#| echo: true
tidy(happiness_model, conf.int = TRUE)
```

::: fragment
```{r}
#| echo: true
glance(happiness_model)
```
:::

## Traduciendo los resultados a matem치ticas {.text-orange-gold}

::: columns
::: {.column width="40%"}
```{r}
#| echo: false
tidy(happiness_model, conf.int = TRUE) |> 
  select(term, estimate)
```

$$
\begin{aligned}
&\widehat{\text{Felicidad}} = \\ 
&\beta_0 + \beta_1 \times \text{Galletas} + \varepsilon
\end{aligned}
$$

$$
\begin{aligned}
&\widehat{\text{Felicidad}} = \\ 
&1.1 + 0.16 \times \text{Galletas} + \varepsilon
\end{aligned}
$$
:::

::: {.column width="60%"}
```{r}
#| echo: false
cookies_base +
  geom_smooth(method = "lm", color = "#0074D9") +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 4))
```
:::
:::

## Interpretaci칩n de los coeficientes {.text-orange-gold}

Un incremento en una unidad de $X$ est치 *asociado* con un incremento (o reducci칩n) promedio de $\beta_1$ unidades en $Y$

$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas$$

$$\widehat{Felicidad} = 1.1 + 0.16 \times Galletas$$

:::{.incremental}

- En *promedio*, una galleta adicional est치 asociado a aumento en la felicidad de 0.16 unidades

- Si no hay consumo de galletas, esperamos que el puntaje de felicidad sea 1.1 unidades
:::


## 쮼s el intercepto importante? {.text-orange-gold}

- La interpretaci칩n del intercepto es importante si en el contexto de los datos:

  1. La variable independiente puede tomar valores iguales o cercanos a cero
  
  2. La variable independiente tiene valores cercanos a cero en los datos observados
  
:::{.incremental}
  
- En caso contrario, el intercepto no tiene ninguna interpretaci칩n pr치ctica

- Veremos m치s ejemplos sobre esto m치s adelante...
:::


## Volvamos a Hollywood Rules  {.text-orange-gold}

- Seg칰n la sabidur칤a popular en Hollywood, el recaudo durante el primer fin de semana es un fuerte predictor del 칠xito comercial de una pel칤cula
- Grafiquemos la relaci칩n entre el recaudo en Estados Unidos y el recaudo en el primer fin de semana para evaluar esta creencia:




## Volvamos a Hollywood Rules  {.text-orange-gold}


```{r}
#| echo: false
#| eval: true
#| fig-align: center

ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```



## Volvamos a Hollywood Rules  {.text-orange-gold}

```{r}
#| echo: true
#| eval: true
hollywood_model <- lm(us_gross ~ opening_gross, data=hollywood)
tidy(hollywood_model, conf.int = TRUE)

```

:::{.fragment}

Entonces nuestro modelo lineal es:

$$\widehat{\text{US Total Gross}} = 5,108,220 + 3.12 \times \text{Opening Gross}$$

:::

:::{.fragment}
쮺u치l es la interpretaci칩n de $\hat{\beta_1}$ en este caso?쯏 de $\hat{\beta_0}$?
:::



##  C칩mo graficar la l칤nea de regresi칩n? {.text-orange-gold}

`geom_smooth(method="lm")`es la funci칩n dentro de ggplot para gr치ficar la l칤nea de regresi칩n y su respectivo intervalo de confianza.


```{r}
#| echo: true
#| eval: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center
#| code-line-numbers: "3"
ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    geom_smooth(method="lm") +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```


##  C칩mo graficar la l칤nea de regresi칩n? {.text-orange-gold}


```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    geom_smooth(method="lm") +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```


## Predicci칩n  {.text-orange-gold}

Seg칰n nuestro modelo, 쯖u치l ser칤a el recaudo en US de una pel칤cula cuyo recaudo en el primer fin de semana fue de \$50,000,000?



$$  
  \begin{aligned}
\widehat{\text{US Gross}} &= 5,108,220 + 3.12 \times \text{Opening Gross} \\
  &= 5,108,220 + 3.12 \times \color{red}{50,000,000} \\
  &= 161,108,220
\end{aligned}
$$


## Predicci칩n  {.text-orange-gold}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 8

model <- lm(us_gross ~ opening_gross , data = hollywood)

# Predict the corresponding y value when x = 50
predicted_y <- predict(model, newdata = data.frame(opening_gross = 50 * 1000000))

# Plot
ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_vline(xintercept = 50, linetype = "dashed", color = "blue") +   # Dashed vertical line at x = 50
  geom_hline(yintercept = predicted_y/ 1000000, linetype = "dashed", color = "blue") + # Dashed horizontal line at predicted y
  geom_point(aes(x = 50, y = predicted_y/ 1000000), color = "red", size = 3) + # Point at (50, predicted_y)
  labs(
    x = "Opening Gross (in millions)",
    y = "US Total Gross (in millions)"
  ) +
  theme_minimal()
```





## 쮼s posible la extrapolaci칩n? {.text-orange-gold}

Extrapolar es tratar de predecir Y fuera del rango de valores de X. Es posible pero no aconsejable.

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 8
# Predict the corresponding y value when x = 80
predicted_y <- predict(model, newdata = data.frame(opening_gross = 80 * 1000000))

# Plot
ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    geom_smooth(method = "lm") +
    geom_vline(xintercept = 80, linetype = "dashed", color = "blue") +   # Dashed vertical line at x = 80
    geom_hline(yintercept = predicted_y/ 1000000, linetype = "dashed", color = "blue") + # Dashed horizontal line at predicted y
    geom_point(aes(x = 80, y = predicted_y/ 1000000), color = "red", size = 3) + # Point at (80, predicted_y)
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) + theme_minimal()

```


## Inferencia de los coeficientes {.text-orange-gold}

Cuando trabajamos con distribuciones muestrales, la idea era que:

$$
\bar{X} \xrightarrow{\text{游 ojal치 游룧} \mu
$$

:::{.fragment}

De igual manera, en el modelo de regresi칩n queremos:

$$
\hat{\beta} \xrightarrow{\text{游 ojal치 游룧} \beta
$$
:::



## Inferencia de los coeficientes {.text-orange-gold}

$$\widehat{\text{US Total Gross}} = 5,108,220 + 3.12 \times \text{Opening Gross}$$

- Es $\beta_1$ diferente de cero?


::: fragment
```{r}
#| echo: true
tidy(hollywood_model, conf.int = TRUE)
```
:::


## M치s pruebas de hip칩tesis {.text-orange-gold}

$$H_0:\beta_1=0$$
$$H_1: \beta_1 \neq 0$$

:::{.fragment}

$$Z=\dfrac{3.12-0}{0.218}=14.3>Z_{\frac{\alpha}{2}}=1.96$$

- Rechazamos la $H_0$ a un nivel de significancia del 5%! 

- El p-value es 7.07e-23 (en notaci칩n cient칤fica), el cual es mucho menor a 0.05. 

:::



# [Regresi칩n Lineal<br>[[M칰ltiple]{.hl .hl-purple}]{style="font-size:75%;"}]{style="color:white"} {#multiple background="linear-gradient(45deg, #4a00e0, #ff0099)"}


## Regresi칩n M칰ltiple {.text-indigo-pink}

No estamos limitados a una sola variable explicativa!

$$
\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n + \varepsilon
$$

:::{.fragment}

```{r}
#| echo: true
hollywood_model <- lm(us_gross ~ opening_gross + budget + sequel, data=hollywood)
```

$$
\widehat{\text{US Gross}} = \hat{\beta_0} + \hat{\beta_1} \text{Opening Gross} + \hat{\beta_2} \text{Budget} + \hat{\beta_3} \text{Sequel}
$$

:::


## Regresi칩n M칰ltiple {.text-indigo-pink}

```{r}
#| echo: true
hollywood_model <- lm(us_gross ~ opening_gross + budget + sequel, data=hollywood)
tidy(hollywood_model, conf.int = TRUE)
```


$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel}
\end{aligned}
$$

## Variables Categ칩ricas vs Variables Continuas {.text-indigo-pink}

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("images/slider-switch-plain-80.jpg")

```


## Variables Categ칩ricas vs Variables Continuas {.text-indigo-pink}

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("images/slider-switch-annotated-80.jpg")

```


# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

set.seed(123)

# Create a tibble with the same slope but different intercepts for professors and students, adding noise
cookies_data <- tibble(
  cookies = rep(1:7, 2),  # Galletas consumidas (1 through 7 for both groups)
  group = rep(c("Profesores", "Estudiantes"), each = 7),  # Group variable
  happiness = c(0.5 + 0.15 * (1:7) + rnorm(7, sd = 0.2),  # Happiness for professors with noise
                1.5 + 0.15 * (1:7) + rnorm(7, sd = 0.2))  # Happiness for students with noise
)


ggplot(cookies_data, aes(x = cookies, y = happiness)) +
  geom_point( size = 3) +  # Points still colored by group for clarity
  geom_smooth(method = "lm", se = FALSE, color = "#0074D9") +  # Single regression line for the entire dataset
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad") +
  theme_minimal(base_size = 14) +
  coord_cartesian(xlim = c(0, 8), ylim = c(0, 3)) +
  scale_x_continuous(breaks = 0:8) +
  theme(panel.grid.minor = element_blank())


```

# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

ggplot(cookies_data, aes(x = cookies, y = happiness)) +
  geom_point(aes(color = group), size = 3) +  # Points still colored by group for clarity
  geom_smooth(method = "lm", se = FALSE, color = "#0074D9") +  # Single regression line for the entire dataset
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad", color = "Grupo") +
  theme_minimal(base_size = 14) +
  coord_cartesian(xlim = c(0, 8), ylim = c(0, 3)) +
  scale_color_manual(values = c("Profesores" = "navy", "Estudiantes" = "darkred")) +
  scale_x_continuous(breaks = 0:8) +
  theme(panel.grid.minor = element_blank())


```

# 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

ggplot(cookies_data, aes(x = cookies, y = happiness, color = group)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE) +  # Add linear regression lines
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad", color = "Grupo") +
  theme_minimal(base_size = 14) +
  coord_cartesian(xlim = c(0, 8), ylim = c(0, 3)) +
  scale_color_manual(values = c("Profesores" = "navy", "Estudiantes" = "darkred")) +
  scale_x_continuous(breaks = 0:8) +
  theme(panel.grid.minor = element_blank())

```


## Variables Categ칩ricas {.text-indigo-pink}


$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas+\hat{\beta_2} \times Estudiante$$

:::{.incremental}

- EL intercepto para las observaciones de los profesores ser치 $\hat{\beta_0}$ porque $Estudiante=0$

- El intercepto para las observaciones de los estudiantes ser치 $\hat{\beta_0}+\hat{\beta_2}$ porque $Estudiante=1$
:::


## Filtrar la variaci칩n {.text-indigo-pink}

- Cada **X** en el modelo explica una porci칩n de la variaci칩n en **Y**

- La interpretaci칩n ac치 es m치s complicada que en el modelo de regresi칩n simple porque s칩lo se puede mover una variable a la vez


## Plantilla para variables continuas {.text-indigo-pink}

Manteniendo todo lo dem치s constante, un incremento de una unidad en **X** est치 asociado con un incremento/reducci칩n promedio de $\beta_n$ en **Y**

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel}
\end{aligned}
$$

:::{.fragment}
Manteniendo todo lo dem치s constante, un incremento de un d칩lar en el recaudo del primer fin de semana est치 asociado con un incremento promedio de 2.99 d칩lares en el recaudo total en US
:::


## Plantilla para variables categ칩ricas {.text-indigo-pink}

Manteniendo todo lo dem치s constante, **Y** es, en promedio, $\beta_n$ unidades mayor/menor para **X**<sub>n</sub> comparado con **X**<sub>omitida</sub>

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel}
\end{aligned}
$$


:::{.fragment}

Manteniendo todo lo dem치s constante, las sequelas est치n asociadas a un recaudo promedio menor, en aproximadamente $11.9 millones, comparadas con las pel칤culas que no son secuelas

:::


## Variable categ칩ricas con m치s de 2 niveles {.text-indigo-pink}

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel} - 15,000,000 \times \text{Trilogy}
\end{aligned}
$$

Si es la primera pel칤cula $Sequel=Trilogy=0$, el modelo es:

$$\widehat{\text{US Gross}} = -8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget}$$


## Variable categ칩ricas con m치s de 2 niveles {.text-indigo-pink}

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel} - 15,000,000 \times \text{Trilogy}
\end{aligned}
$$


Si es trilog칤a, entonces $Sequel=0$ y $Trilogy=1$. En este caso, el modelo es:

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 15,000,000 
\end{aligned}
$$

Manteniendo lo dem치s constante, estimamos que una trilog칤a tendr치, en promedio, un recaudo 15 millones de d칩lares menor que una primera entrega

