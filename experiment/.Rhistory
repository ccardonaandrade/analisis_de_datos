coffee_ratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv')
glimpse(coffee_ratings)
ggplot(coffee_rating, aes(x=aroma, y=total_cup_points)) +
geom_point()
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point()
coffee_ratings <- coffee_ratings %>%
filter(!aroma<5)
glimpse(coffee_ratings)
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point()
coffee_ratings <- coffee_ratings %>%
filter(!aroma<6)
glimpse(coffee_ratings)
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point()
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point() +
theme_minimal()
ggplot(coffee_ratings, aes(x=sweetness, y=total_cup_points)) +
geom_point() +
theme_minimal()
ggplot(coffee_ratings, aes(x=flavor, y=total_cup_points)) +
geom_point() +
theme_minimal()
ggplot(coffee_ratings, aes(x=acidity, y=total_cup_points)) +
geom_point() +
theme_minimal()
ggplot(coffee_ratings, aes(x=moisture, y=total_cup_points)) +
geom_point() +
theme_minimal()
ggplot(coffee_ratings, aes(x=log(moisture), y=total_cup_points)) +
geom_point() +
theme_minimal()
ggplot(coffee_ratings, aes(x=log(1+moisture), y=total_cup_points)) +
geom_point() +
theme_minimal()
ggplot(coffee_ratings, aes(x=aftertaste, y=total_cup_points)) +
geom_point() +
theme_minimal()
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point() +
theme_minimal()
coffee_ratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv')
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point() +
theme_minimal()
coffee_ratings <- coffee_ratings %>%
filter(!aroma<2)
glimpse(coffee_ratings)
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point() +
theme_minimal()
coffee_ratings <- coffee_ratings %>%
mutate(comedy = ifelse(country_of_origina == "Colombia", 1, 0))
coffee_ratings <- coffee_ratings %>%
mutate(comedy = ifelse(country_of_origin == "Colombia", 1, 0))
coffee_model <- lm(total_cup_points ~ aroma + comedy, data=coffee_ratings)
tidy(coffee_model)
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point() + geom_smooth(method="lm")+
theme_minimal()
ggplot(coffee_ratings, aes(x=aroma)) +
geom_density() + vline(x=68)
ggplot(coffee_ratings, aes(x=aroma)) +
geom_density() + geom_vline(x=68)
ggplot(coffee_ratings, aes(x=aroma)) +
geom_density() + geom_vline(x=68) +
theme_minimal()
ggplot(coffee_ratings, aes(x=aroma)) +
geom_density() + geom_vline(xintercept =68) +
theme_minimal()
ggplot(coffee_ratings, aes(x=total_cup_points)) +
geom_density() + geom_vline(xintercept =68) +
theme_minimal()
ggplot(coffee_ratings, aes(x=total_cup_points)) +
geom_density() + geom_vline(xintercept =68 , linetype="dashed") +
theme_minimal()
summary(coffee_ratings$comedy)
glimpse(coffee_ratings)
coffee_ratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv')
coffee_ratings <- coffee_ratings %>%
select(total_cup_points,species,country_of_origin,
aroma,flavour,aftertase, acidity,body,balance)
coffee_ratings <- coffee_ratings %>%
select(total_cup_points,species,country_of_origin,
aroma,flavor,aftertase, acidity,body,balance)
coffee_ratings <- coffee_ratings %>%
select(total_cup_points,species,country_of_origin,
aroma,flavor,aftertaste, acidity,body,balance)
View(coffee_ratings)
glimpse(coffee_ratings)
ggplot(coffee_ratings, aes(x=body, y=total_cup_points)) +
geom_point() + geom_smooth(method="lm")+
theme_minimal()
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point() + geom_smooth(method="lm")+
theme_minimal()
ggplot(coffee_ratings, aes(x=body, y=total_cup_points)) +
geom_point() + geom_smooth(method="lm")+
theme_minimal()
coffee_ratings <- coffee_ratings %>%
filter(!total_cup_points==0)
glimpse(coffee_ratings)
ggplot(coffee_ratings, aes(x=body, y=total_cup_points)) +
geom_point() + geom_smooth(method="lm")+
theme_minimal()
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point() + geom_smooth(method="lm")+
theme_minimal()
coffee_model <- lm(total_cup_points ~ aroma, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
ggplot(coffee_ratings, aes(x=total_cup_points)) +
geom_density() + geom_vline(xintercept =38 , linetype="dashed") +
theme_minimal()
coffee_ratings <- coffee_ratings %>%
mutate(colombia = ifelse(country_of_origin == "Colombia", 1, 0))
coffee_model <- lm(total_cup_points ~ aroma + colombia, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
coffee_model <- lm(total_cup_points ~ aroma, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
coffee_ratings <- coffee_ratings %>%
mutate(colombia = ifelse(country_of_origin == "Colombia", 1, 0))
coffee_model <- lm(total_cup_points ~ aroma + colombia, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
ggplot(coffee_ratings, aes(x=total_cup_points)) +
geom_density() + geom_vline(xintercept =38 , linetype="dashed") +
theme_minimal()
coffee_ratings <- coffee_ratings %>%
mutate(colombia = ifelse(country_of_origin == "Colombia", 1, 0))
coffee_model <- lm(total_cup_points ~ aroma + colombia, data=coffee_ratings)
augment(coffee_model) %>%
ggplot(aes(x = .fitted, y = .resid)) +
geom_point() +
geom_smooth(se = FALSE) +
labs(x = "Valores predichos", y = "Residuos")
augment(coffee_model) %>%
ggplot(aes(x = .resid)) +
geom_histogram() +
labs(title = "Distribuci√≥n de los residuos",
x = "Residuos") +
theme_minimal()
glance(coffee_model)
coffee_model <- lm(total_cup_points ~ aroma, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
glance(coffee_model)
coffee_model <- lm(total_cup_points ~ aroma + colombia, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
glance(coffee_model)
coffee_model <- lm(total_cup_points ~ flavor, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
glance(coffee_model)
coffee_model <- lm(total_cup_points ~ body, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
glance(coffee_model)
coffee_model <- lm(total_cup_points ~ flavor, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
coffee_model <- lm(total_cup_points ~ flavor, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
glance(coffee_model)
ggplot(coffee_ratings, aes(x=flavor, y=total_cup_points)) +
geom_point() + geom_smooth(method="lm")+
theme_minimal()
ggplot(coffee_ratings, aes(x=aroma, y=total_cup_points)) +
geom_point() + geom_smooth(method="lm")+
theme_minimal()
coffee_model <- lm(total_cup_points ~ flavor + aroma, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
glance(coffee_model)
coffee_model <- lm(total_cup_points ~ flavor + aroma + colombia, data=coffee_ratings)
tidy(coffee_model, conf.int = TRUE)
library(kableExtra)
library(tidyverse)
library(broom)
library(tidyverse)
blizzard_salary
help(blizzard_salary)
??blizzard_salary
install.packages("openintro")
data <- blizzard_salary
library(openintro)
data <- blizzard_salary
summary(data$current_salary)
View(data)
ggplot(data, x=current_salary)+geom_boxplot()
ggplot(data, aes(x=current_salary))+geom_boxplot()
View(data)
salary_type <- unique(data$salary_type)
data <- data %>%
mutate(salaried = ifelse(salary_type == "year" | salary_type == "week", 1, 0))
View(data)
data |>
group_by(salaried) |>
summarize(
mean_annual_salary = mean(annual_salary),
median_annual_salary = median(annual_salary)
)
data |>
group_by(salaried) |>
summarize(
mean_annual_salary = mean(current_salary),
median_annual_salary = median(current_salary)
)
blizzard_salary <- blizzard_salary
blizzard_salary <- blizzard_salary |>
mutate(
annual_salary = case_when(
salary_type == "week" ~ current_salary * 52,
salary_type == "hour" ~ current_salary * 40 * 52,
TRUE ~ current_salary
),
performance_rating = if_else(performance_rating == "Developing", "Poor", performance_rating)
) |>
filter(salary_type != "week") |>
mutate(
salary_type = if_else(salary_type == "hour", "Hourly", "Salaried")
) |>
filter(!is.na(annual_salary)) |>
select(percent_incr, salary_type, annual_salary, performance_rating)
blizzard_salary |>
group_by(salary_type) |>
summarize(
mean_annual_salary = mean(annual_salary),
median_annual_salary = median(annual_salary)
)
ggplot(data, aes(x=annual_salary))+geom_boxplot()
ggplot(blizzard_salary, aes(x=annual_salary))+geom_boxplot()
summary(blizzard_salary$annual_salary)
library(tidyverse)
library(openintro)
blizzard_salary <- blizzard_salary
View(blizzard_salary)
blizzard_salary <- blizzard_salary |>
mutate(
annual_salary = case_when(
salary_type == "week" ~ current_salary * 52,
salary_type == "hour" ~ current_salary * 40 * 52,
TRUE ~ current_salary
),
performance_rating = if_else(performance_rating == "Developing", "Poor", performance_rating)
) |>
filter(salary_type != "week") |>
mutate(
salary_type = if_else(salary_type == "hour", "Hourly", "Salaried")
) |>
filter(!is.na(annual_salary))
View(blizzard_salary)
blizzard_salary %>% unique(filter(location))
blizzard_salary %>% unique(select(location))
blizzard_salary %>% select(location)
blizzard_salary %>% select(location) %>% pull()
blizzard_salary %>% select(location) %>% distinct() %>% pull()
blizzard_salary %>% group_by(location) %>% summarise(mean=mean(annual_salary))
blizzard_salary %>% group_by(location) %>% summarise(mean=count(annual_salary))
blizzard_salary %>% group_by(location) %>% summarise(mean=nrows(annual_salary))
blizzard_salary %>% group_by(location) %>% summarise(count=n())
blizzard_salary <- blizzard_salary
library(tidyverse)
library(tidymodels)
library(openintro)
library(scales)
library(ggmosaic)
library(tidymodels)
blizzard_salary <- blizzard_salary
blizzard_salary <- blizzard_salary |>
mutate(
annual_salary = case_when(
salary_type == "week" ~ current_salary * 52,
salary_type == "hour" ~ current_salary * 40 * 52,
TRUE ~ current_salary
),
performance_rating = if_else(performance_rating == "Developing", "Poor", performance_rating)
) |>
filter(salary_type != "week") |>
mutate(
salary_type = if_else(salary_type == "hour", "Hourly", "Salaried")
) |>
filter(!is.na(annual_salary)) |>
select(percent_incr, salary_type, annual_salary, performance_rating)
View(blizzard_salary)
model1 <- lm(percent_incr + annual_salary + factor(salary_type), blizzard_salary)
model1 <- lm(percent_incr + annual_salary + factor(salary_type), data= blizzard_salary)
library(broom)
model1 <- lm(percent_incr + annual_salary + factor(salary_type), data= blizzard_salary)
model1 <- lm(percent_incr ~ annual_salary + factor(salary_type), data= blizzard_salary)
tidy(model1)
glance(model1)
model1 <- lm(percent_incr ~ annual_salary + factor(performance_rating), data= blizzard_salary)
tidy(model1)
glance(model1)
model1 <- lm(percent_incr ~ annual_salary, data= blizzard_salary)
tidy(model1)
glance(model1)
View(blizzard_salary)
blizzard_salary <- blizzard_salary %>%
mutate(new=percent_incr+1.5)
model1 <- lm(percent_incr ~ annual_salary, data= blizzard_salary)
tidy(model1)
glance(model1)
model2 <- lm(new ~ annual_salary, data= blizzard_salary)
tidy(model2)
blizzard_salary <- blizzard_salary %>%
mutate(new_salary=annual_salary*1.5)
model1 <- lm(percent_incr ~ annual_salary, data= blizzard_salary)
tidy(model1)
glance(model1)
model2 <- lm(percent_incr ~ new_salary, data= blizzard_salary)
tidy(model2)
View(blizzard_salary)
library(tidyverse)
set.seed(123)
# Simulate data
n <- 500  # Number of observations
# Black Voting Age Population (continuous between 0 and 1)
black_voting_age_population <- runif(n, min = 0, max = 1)
# Create a linear probability model with noise
true_linear_probs <- 2 * black_voting_age_population - 0.5  # Linear model, slope ensures that predictions can go outside [0,1]
# Adding noise directly to the probabilities to make it less deterministic
noisy_probs <- true_linear_probs + rnorm(n, mean = 0, sd = 0.5)  # Adding some noise to make the outcome more random
# Generate binary outcome based on the noisy probabilities
black_representative_elected <- ifelse(noisy_probs > 0.5, 1, 0)
# Combine data into a data frame
data <- data.frame(
Black_Voting_Age_Population = black_voting_age_population,
Black_Representative_Elected = black_representative_elected
)
# Plot the data and the linear regression line
ggplot(data, aes(x = Black_Voting_Age_Population, y = Black_Representative_Elected)) +
geom_point(alpha = 0.8, color = "blue") +
geom_smooth(method = "lm", se = FALSE, color = "red") +  # Linear regression line
labs(
title = "Linear Regression Predicting Probabilities Beyond [0, 1]",
x = "Black Voting Age Population",
y = "Black Representative Elected"
) +
theme_minimal() +
theme(plot.title = element_text(size = 16, face = "bold"))
ggplot(data, aes(x = Black_Voting_Age_Population, y = Black_Representative_Elected)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(y = "Getting 7+ hours of sleep") +
theme_minimal()
ggplot(data, aes(x = Black_Voting_Age_Population, y = Black_Representative_Elected)) +
geom_point() +
geom_hline(yintercept = c(0,1), lty = 2) +
stat_smooth(method = "lm",fullrange = TRUE, se = FALSE) +
labs(y = "P(7+ hours of sleep)") +
xlim(-0.1, 1.1) +
ylim(-1, 2) +
theme_minimal()
ggplot(data, aes(x = Black_Voting_Age_Population, y = Black_Representative_Elected)) +
geom_point() +
geom_hline(yintercept = c(0,1), lty = 2) +
stat_smooth(method ="glm", method.args = list(family = "binomial"),
fullrange = TRUE, se = FALSE) +  labs(y = "P(7+ hours of sleep)") +
xlim(-0.1, 1.1) +
ylim(-1, 2) +
theme_minimal()
ggplot(data, aes(x = Black_Voting_Age_Population, y = Black_Representative_Elected)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(y = "Getting 7+ hours of sleep") +
theme_minimal()
0.221/0.779
exp(0.00361)
exp(0.00361)/1+exp(0.00361)
exp(-1.30)/1+exp(-1.30)
exp(-1.30)/(1+exp(-1.30))
exp(-1.30)
setwd("C:/Users/ccard/OneDrive/Documentos/GitHub/analisis_de_datos/clase10")
library(tidyverse)
library(janitor)
library(knitr)
library(broom)
default <- read_csv("credit_demographics.csv")
default <- default %>%
clean_names()
logit_model2 <- glm(default ~ age + sex + marriage, data = default, family = "binomial")
tidy(logit_model2)
logit_model2 <- glm(default ~ age + factor(sex) + factor(marriage), data = default, family = "binomial")
tidy(logit_model2)
augment(logit_model2, newdata = default) %>%
mutate(
.pred_class = if_else(.fitted >= 0.5, 1, 0)) %>%
count(default, .pred_class)
logit_model2 <- glm(default ~ age + factor(sex) + factor(marriage), data = default, family = "binomial")
default$predprob <- predict(logit_model2, newdata = default, type = "response")
default <- default %>%
mutate(pred_class = if_else(predprob >= 0.3, 1, 0))
confusion_matrix <- default %>%
count(default, pred_class)
confusion_matrix
default <- default %>%
mutate(pred_class = if_else(predprob >= 0.2, 1, 0))
confusion_matrix <- default %>%
count(default, pred_class)
confusion_matrix
View(default)
lin_model <- lm(default ~ age + factor(sex) + factor(marriage), data = default)
tidy(lin_model)
defalt %>% select(marriage) %>% distinct() %>% pull()
default %>% select(marriage) %>% distinct() %>% pull()
library(readxl)
library(broom)
library(janitor)
library(tidyverse)
setwd("C:/Users/ccard/OneDrive/Documentos/GitHub/analisis_de_datos/experiment")
data <- read_csv("marketing_AB.csv")
data <- read_csv("marketing_AB.csv")
View(data)
data <- data %>%
clean_names()
glimpse(data)
View(data)
data <- data %>%
mutate(treatment = ifelse(test_group == "ad", 1, 0))
View(data)
data <- data %>%
mutate(treatment = ifelse(test_group == "ad", 1, 0),
converted_num = ifelse(converted == TRUE, 1, 0))
View(data)
lin_model <- lm(converted_num ~ treatment, data)
tidy(lin_model)
View(data)
lin_model2 <- lm(converted_num ~ total_ads, data)
tidy(lin_model2)
summary(data$total_ads)
lin_model2 <- lm(total_ads ~ treatment, data)
tidy(lin_model2)
lin_model2 <- lm(most_ads_hour ~ treatment, data)
tidy(lin_model2)
summary(data$most_ads_hour)
# Summarize data to get mean and confidence intervals for each group
summary_data <- data %>%
group_by(treatment) %>%
summarise(
mean_converted = mean(converted_num, na.rm = TRUE),
ci_low = mean_converted - qt(0.975, df = n() - 1) * sd(converted_num, na.rm = TRUE) / sqrt(n()),
ci_high = mean_converted + qt(0.975, df = n() - 1) * sd(converted_num, na.rm = TRUE) / sqrt(n())
)
# Plot the bar graph with confidence intervals
ggplot(summary_data, aes(x = as.factor(treatment), y = mean_converted)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.6) +
geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.2, color = "red") +
labs(x = "Treatment Group (0 = Control, 1 = Treated)", y = "Mean Converted",
title = "Conversion Rate by Treatment Group") +
theme_minimal()
tidy(lin_model)
tidy(lin_model2, conf.int = TRUE)
tidy(lin_model, conf.int = TRUE)
0.0179+0.00769
t_test_result <- t.test(converted_num ~ treatment, data = data)
t_test_result
# Summarize data to get mean and confidence intervals for each group
summary_data <- data %>%
group_by(treatment) %>%
summarise(
mean_converted = mean(converted_num, na.rm = TRUE),
ci_low = mean_converted - 1.96 * sd(converted_num, na.rm = TRUE) / sqrt(n()),
ci_high = mean_converted + 1.96 * sd(converted_num, na.rm = TRUE) / sqrt(n())
)
# Plot the bar graph with confidence intervals
ggplot(summary_data, aes(x = as.factor(treatment), y = mean_converted)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.6) +
geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.2, color = "red") +
labs(x = "Treatment Group (0 = Control, 1 = Treated)",
y = "Mean Converted",
title = "Conversion Rate by Treatment Group") +
theme_minimal()
t_test_result <- t.test(converted_num ~ treatment, data = data)
t_test_result
# Plot the bar graph with confidence intervals
ggplot(summary_data, aes(x = as.factor(treatment), y = mean_converted)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.6) +
geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.2, color = "red") +
labs(x = "Treatment Group (0 = Control, 1 = Treated)",
y = "Mean Converted",
title = "Conversion Rate by Treatment Group") + limits(0, 0.03)
# Plot the bar graph with confidence intervals
ggplot(summary_data, aes(x = as.factor(treatment), y = mean_converted)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.6) +
geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.2, color = "red") +
labs(x = "Treatment Group (0 = Control, 1 = Treated)",
y = "Mean Converted",
title = "Conversion Rate by Treatment Group") +
ylim(0, 0.03) + # Use ylim instead of limits
theme_minimal()
data %>%
group_by(treatment) %>%
summarise(mean_converted = mean(converted_num, na.rm = TRUE))
data %>%
group_by(treatment) %>%
summarise(mean_converted = mean(converted_num))
# Summarize data to get mean and confidence intervals for each group
summary_data <- data %>%
group_by(treatment) %>%
summarise(
mean_ads = mean(total_ads, na.rm = TRUE),
ci_low = mean_ads - 1.96 * sd(total_ads, na.rm = TRUE) / sqrt(n()),
ci_high = mean_ads + 1.96 * sd(total_ads, na.rm = TRUE) / sqrt(n())
)
# Plot the bar graph with confidence intervals
ggplot(summary_data, aes(x = as.factor(treatment), y = mean_ads)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black", width = 0.6) +
geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.2, color = "red") +
labs(x = "Treatment Group (0 = Control, 1 = Treated)",
y = "Mean Converted",
title = "Conversion Rate by Treatment Group") +
theme_minimal()
glimpse(data)
mean(data$converted_num)
mean(data$treatment)
